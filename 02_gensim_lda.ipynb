{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling using Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.corpora import Dictionary\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import json\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JSONCorpus:\n",
    "    \n",
    "    def __init__(self, dpath):\n",
    "        self.dpath = dpath\n",
    "        self.dictionary = Dictionary(self._gen_documents())\n",
    "        \n",
    "    def _gen_documents(self):\n",
    "        # An auxiliary generator\n",
    "        for fname in os.listdir(self.dpath):\n",
    "            with open(os.path.join(self.dpath, fname), 'r', encoding='utf-8') as file:\n",
    "                tokenized_doc = json.load(file)   \n",
    "                yield tokenized_doc\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for doc in self._gen_documents():\n",
    "            yield doc\n",
    "            \n",
    "class BoWCorpus:\n",
    "    \n",
    "    def __init__(self, corpus, dictionary):\n",
    "        self.corpus = corpus\n",
    "        self.dictionary = dictionary\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for doc in self.corpus:\n",
    "            yield self.dictionary.doc2bow(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_PREPROCESSED_DATA = 'preprocessed_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = JSONCorpus(DIR_PREPROCESSED_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens before filtering: 85940\n",
      "Total number of filtered tokens: 56915\n",
      "Number of tokens after filtering: 29025\n"
     ]
    }
   ],
   "source": [
    "MIN_DF = 5\n",
    "MAX_DF_RATIO = 0.5\n",
    "\n",
    "num_orig = len(corpus.dictionary)\n",
    "corpus.dictionary.filter_extremes(no_below=MIN_DF, no_above=MAX_DF_RATIO, keep_n=None)\n",
    "\n",
    "print(f'Number of tokens before filtering: {num_orig}')\n",
    "print(f'Total number of filtered tokens: {num_orig - len(corpus.dictionary)}')\n",
    "print(f'Number of tokens after filtering: {len(corpus.dictionary)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = BoWCorpus(corpus, corpus.dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA model parameters\n",
    "UPDATE_EVERY = 1 # Online learning\n",
    "NUM_PASSES = 5 # Sufficient - selected during convergence monitoring\n",
    "NUM_ITERATIONS = 200 # Sufficient - selected during convergence monitoring\n",
    "CHUNK_SIZE = 2000\n",
    "RANDOM_STATE = 42\n",
    "LIST_NUM_TOPICS = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "\n",
    "# Coherence model parameters\n",
    "COH_METRIC = 'c_v'\n",
    "COH_NUM_PROCESSES = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_scores = {}\n",
    "\n",
    "for num_topics in tqdm(LIST_NUM_TOPICS):\n",
    "    lda_model = LdaModel(corpus=bow_corpus,\n",
    "                         id2word=corpus.dictionary, \n",
    "                         num_topics=num_topics, \n",
    "                         passes=NUM_PASSES, \n",
    "                         iterations=NUM_ITERATIONS,\n",
    "                         chunksize=CHUNK_SIZE, \n",
    "                         random_state=RANDOM_STATE, \n",
    "                         update_every=UPDATE_EVERY)\n",
    "    coherence_model = CoherenceModel(lda_model, texts=corpus, dictionary=corpus.dictionary, coherence=COH_METRIC, processes=COH_NUM_PROCESSES)\n",
    "    coherence_scores[num_topics] = coherence_model.get_coherence()\n",
    "    print(f'Num topics: {num_topics} | Coherence: {coherence_scores[num_topics]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended number of topics (based on Coherence score): 30\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 30\n",
    "#NUM_TOPICS = max(coherence_scores, key=coherence_scores.get)\n",
    "print(f'Recommended number of topics (based on Coherence score): {NUM_TOPICS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(coherence_scores.keys())\n",
    "y = list(coherence_scores.values())\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(x, y)\n",
    "plt.title('Coherence score vs. number of topics')\n",
    "plt.xlabel('Number of topics')\n",
    "plt.ylabel('Coherence score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = LdaModel(corpus=bow_corpus,\n",
    "                       id2word=corpus.dictionary,  \n",
    "                       num_topics=NUM_TOPICS,\n",
    "                       passes=NUM_PASSES,\n",
    "                       iterations=NUM_ITERATIONS,\n",
    "                       chunksize=CHUNK_SIZE,\n",
    "                       random_state=RANDOM_STATE,\n",
    "                       update_every=UPDATE_EVERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = gensim.models.ldamodel.LdaModel.load('models/gensim/lda/lda_30/lda_30.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: obviněný|čin|trestný|trestní|jednání|skutek|znak|zákoník|pachatel|podstata\n",
      "Topic: 1 \n",
      "Words: společnost|obchodní|člen|ob|družstvo|valný|hromada|společník|jednatel|představenstvo\n",
      "Topic: 2 \n",
      "Words: pohledávka|věřitel|dlužník|zástavní|závazek|dluh|smlouva|úkon|postoupení|výše\n",
      "Topic: 3 \n",
      "Words: advokát|žalobce|zástupce|poplatek|nedostatek|podání|zastoupení|právnický|vzdělání|osvobození\n",
      "Topic: 4 \n",
      "Words: přípustnost|dovolatelka|uveřejněný|praxe|řešení|rozhodovací|procesní|ustálený|číslo|stanovisko\n",
      "Topic: 5 \n",
      "Words: pozemek|nemovitost|žalobce|vlastník|vlastnický|vlastnictví|katastrální|předmětný|parc|stavba\n",
      "Topic: 6 \n",
      "Words: smlouva|kupní|smluvní|cena|uzavřený|úkon|platný|strana|platnost|dohoda\n",
      "Topic: 7 \n",
      "Words: služba|vojenský|pravomoc|mezinárodní|český|článek|republika|bývalý|svoboda|povinnost\n",
      "Topic: 8 \n",
      "Words: žalobkyně|částka|nárok|žaloba|výše|zaplacení|prodlení|plnění|úrok|doba\n",
      "Topic: 9 \n",
      "Words: stát|majetek|správní|orgán|nárok|vydání|úřad|státní|veřejný|dražba\n",
      "Topic: 10 \n",
      "Words: pracovní|práce|zaměstnanec|poměr|žalobce|zaměstnavatel|doba|výpověď|mzda|povinnost\n",
      "Topic: 11 \n",
      "Words: obviněný|trest|trestní|trestný|svoboda|odnětí|čin|okresní|uložený|zákoník\n",
      "Topic: 12 \n",
      "Words: manžel|společný|podíl|vypořádání|žalobkyně|jmění|spoluvlastnictví|nemovitost|spoluvlastník|majetek\n",
      "Topic: 13 \n",
      "Words: poškozený|obviněný|jednání|zákoník|čin|zdraví|útok|trestný|násilí|těžký\n",
      "Topic: 14 \n",
      "Words: vozidlo|provoz|motorový|nehoda|dopravní|řidič|povinnost|komunikace|automobil|jízda\n",
      "Topic: 15 \n",
      "Words: exekuce|exekuční|výkon|rozhodčí|nařízení|exekutor|návrh|zastavení|titul|nález\n",
      "Topic: 16 \n",
      "Words: byt|bytový|nájem|nájemní|dům|nájemce|obč|nájemné|užívání|předmětný\n",
      "Topic: 17 \n",
      "Words: příslušný|příslušnost|okresní|český|návrh|republika|pojistný|místní|přikázání|obvod\n",
      "Topic: 18 \n",
      "Words: škoda|daň|odpovědnost|povinnost|výše|způsobený|zboží|daňový|hodnota|vznik\n",
      "Topic: 19 \n",
      "Words: insolvenční|konkursní|podstata|konkurs|správce|majetek|dlužník|úpadce|věřitel|pohledávka\n",
      "Topic: 20 \n",
      "Words: dílo|stavební|stavba|vada|žalobce|provedený|práce|dům|zařízení|cena\n",
      "Topic: 21 \n",
      "Words: trestní|obviněný|soudce|státní|veřejný|stíhání|zástupce|orgán|hlavní|zasedání\n",
      "Topic: 22 \n",
      "Words: lhůta|žaloba|odvolání|podání|návrh|žalobce|vada|doručení|směnka|jednání\n",
      "Topic: 23 \n",
      "Words: důkaz|obviněný|provedený|dokazování|hodnocení|stav|výpověď|skutek|zjištěný|svědek\n",
      "Topic: 24 \n",
      "Words: republika|český|trest|trestný|čin|látka|odsouzený|odsouzení|návrh|činnost\n",
      "Topic: 25 \n",
      "Words: posudek|znalecký|znalec|zdravotní|stav|mudr|péče|následek|obor|odborný\n",
      "Topic: 26 \n",
      "Words: žalobce|význam|zásadní|přípustnost|stránka|vyhláška|odměna|advokát|částka|potvrzený\n",
      "Topic: 27 \n",
      "Words: částka|výše|společnost|finanční|účet|peníze|smlouva|úvěr|poškozený|podvod\n",
      "Topic: 28 \n",
      "Words: dítě|zletilý|dědictví|zůstavitel|matka|otec|dědic|dědický|povinnost|výživné\n",
      "Topic: 29 \n",
      "Words: žalobce|ústavní|újma|majetkový|přiměřený|postup|ochrana|okolnost|nález|strana\n"
     ]
    }
   ],
   "source": [
    "#vypsat témata\n",
    "for idx, topic in final_model.show_topics(formatted=False, num_words= 10, num_topics=50):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, '|'.join([w[0] for w in topic])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(7, 0.015429493), (23, 0.017726526), (28, 0.048715953), (24, 0.05144313), (0, 0.056889653), (2, 0.06900414), (22, 0.06902706), (29, 0.0909741), (6, 0.09938011), (16, 0.10015463), (13, 0.10404118), (12, 0.11528685), (26, 0.15590431)]\n"
     ]
    }
   ],
   "source": [
    "#vypsat téma dokumentu, který se převede na doc2bow\n",
    "rozhodnuti_path = \"C:/Users/novotte5/Disk Google/PrF MUNI/Dr/textanalysis/caselawanalysis/03_muni_research/preprocessed_data/rozhodnuti-29_Cdo_3050_2015.json\"\n",
    "with open(rozhodnuti_path, 'r', encoding='utf-8') as file:\n",
    "    rozhodnuti = json.load(file)\n",
    "    rozhodnuti_bow = bow_corpus.dictionary.doc2bow(rozhodnuti)\n",
    "    list_topics = final_model.get_document_topics(rozhodnuti_bow)\n",
    "    #print(list_topics)\n",
    "    #print(final_model[rozhodnuti_bow]) #jiné způsoby vypsání\n",
    "    #print(final_model.show_topic(29))\n",
    "    \n",
    "#seřadit od nejpravděpodobnějších    \n",
    "def Sort_Tuple(list_topics, reverse = True):\n",
    "    list_topics.sort(key = lambda x: x[1])  \n",
    "    return list_topics\n",
    "print(Sort_Tuple(list_topics))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dominant_topic(doc_bow):\n",
    "    \"\"\"Returns a list of the most dominant topics based on topic probability, one per each document from the input corpus. key=lambda x: x[1]  \n",
    "    \"\"\"\n",
    "    return sorted(final_model.get_document_topics(doc_bow, minimum_probability=0.0), reverse=True)\n",
    "\n",
    "def create_df(corpus, num_documents):\n",
    "    \"\"\"Creates an auxiliary data frame which holds data for further visualizations.\n",
    "    \"\"\"\n",
    "    words = []\n",
    "    word_counts = []\n",
    "    dominant_topics = []\n",
    "    \n",
    "    for doc in tqdm(corpus, total=num_documents):\n",
    "        doc_bow = corpus.dictionary.doc2bow(doc)\n",
    "        words.append(doc)\n",
    "        word_counts.append(len(doc))\n",
    "        dominant_topics.append(get_dominant_topic(doc_bow))\n",
    "        \n",
    "    return pd.DataFrame({'words': words, \n",
    "                         'word_count': word_counts, \n",
    "                         'dominant_topic': dominant_topics})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca4b9d5699114814b16986cdba3ca906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=111187.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_documents = create_df(corpus=corpus, num_documents=corpus.dictionary.num_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>word_count</th>\n",
       "      <th>dominant_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[den, policejní, orgán, policie, útvar, odhalo...</td>\n",
       "      <td>272</td>\n",
       "      <td>[(29, 0.11127229), (28, 0.0001544528), (27, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[vztahující, skutkův, zjištění, skutkový, věta...</td>\n",
       "      <td>18199</td>\n",
       "      <td>[(29, 0.12763977), (28, 0.02659887), (27, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[návrh, soud, porušení, podmínka, výkon, trest...</td>\n",
       "      <td>18218</td>\n",
       "      <td>[(29, 0.051871605), (28, 0.008504843), (27, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[dohoda, směnečný, vyplňovací, prohlášení, spo...</td>\n",
       "      <td>1109</td>\n",
       "      <td>[(29, 0.052658044), (28, 0.021583317), (27, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[rozhodnutí, soud, insolvenční, řízení, vedený...</td>\n",
       "      <td>669</td>\n",
       "      <td>[(29, 0.09750162), (28, 8.6947766e-05), (27, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               words  word_count  \\\n",
       "0  [den, policejní, orgán, policie, útvar, odhalo...         272   \n",
       "1  [vztahující, skutkův, zjištění, skutkový, věta...       18199   \n",
       "2  [návrh, soud, porušení, podmínka, výkon, trest...       18218   \n",
       "3  [dohoda, směnečný, vyplňovací, prohlášení, spo...        1109   \n",
       "4  [rozhodnutí, soud, insolvenční, řízení, vedený...         669   \n",
       "\n",
       "                                      dominant_topic  \n",
       "0  [(29, 0.11127229), (28, 0.0001544528), (27, 0....  \n",
       "1  [(29, 0.12763977), (28, 0.02659887), (27, 0.01...  \n",
       "2  [(29, 0.051871605), (28, 0.008504843), (27, 0....  \n",
       "3  [(29, 0.052658044), (28, 0.021583317), (27, 0....  \n",
       "4  [(29, 0.09750162), (28, 8.6947766e-05), (27, 0...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_documents.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_documents.to_csv('dominant_topics.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of document word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 7))\n",
    "sns.distplot(df_documents['word_count'])\n",
    "plt.title('Distribution of document word counts')\n",
    "plt.xlabel('Word count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of topic sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 7))\n",
    "sns.countplot(df_documents['dominant_topic'])\n",
    "plt.title('Number of documents per topic')\n",
    "plt.xlabel('Topic ID')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(df_documents['dominant_topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MC_6_TOPICS = [x[0] for x in counter.most_common(6)]\n",
    "LC_6_TOPICS = [x[0] for x in counter.most_common()[-1:-7:-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions of word counts across 6 most frequent topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = 2\n",
    "ncol = 3\n",
    "\n",
    "fig, ax = plt.subplots(nrow, ncol, figsize=(23, 10), sharex='row')\n",
    "\n",
    "for i in range(nrow):\n",
    "    for j in range(ncol):\n",
    "        topic_id = MC_6_TOPICS[(i+1) * j]\n",
    "        ax[i, j].set_title(f'Topic: {topic_id}')\n",
    "        sns.distplot(df_documents.query(f'dominant_topic == {topic_id}')['word_count'], ax=ax[i, j])\n",
    "        ax[i, j].set_xlabel('Word count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions of word counts across 6 least frequent topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = 2\n",
    "ncol = 3\n",
    "\n",
    "fig, ax = plt.subplots(nrow, ncol, figsize=(23, 10), sharex='row')\n",
    "\n",
    "for i in range(nrow):\n",
    "    for j in range(ncol):\n",
    "        topic_id = LC_6_TOPICS[(i+1) * j]\n",
    "        ax[i, j].set_title(f'Topic: {topic_id}')\n",
    "        sns.distplot(df_documents.query(f'dominant_topic == {topic_id}')['word_count'], ax=ax[i, j])\n",
    "        ax[i, j].set_xlabel('Word count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word clouds for 6 most frequent topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = 2\n",
    "ncol = 3\n",
    "fig, ax = plt.subplots(nrow, ncol, figsize=(25, 10), sharex='row')\n",
    "aux_id = 0\n",
    "\n",
    "for i in range(nrow):\n",
    "    for j in range(ncol):\n",
    "        topic_id = MC_6_TOPICS[(aux_id)]\n",
    "        aux_id += 1\n",
    "        wordcloud = WordCloud(background_color='white', collocations=False, max_words=20).generate_from_frequencies(dict(final_model.show_topic(topic_id, topn=20)))\n",
    "        ax[i, j].set_title(f'Topic: {topic_id}')\n",
    "        ax[i, j].imshow(wordcloud)\n",
    "        ax[i, j].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word clouds for 6 least frequent topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = 2\n",
    "ncol = 3\n",
    "fig, ax = plt.subplots(nrow, ncol, figsize=(25, 10), sharex='row')\n",
    "aux_id = 0\n",
    "\n",
    "for i in range(nrow):\n",
    "    for j in range(ncol):\n",
    "        topic_id = LC_6_TOPICS[(aux_id)]\n",
    "        aux_id += 1\n",
    "        wordcloud = WordCloud(background_color='white', collocations=False, max_words=20).generate_from_frequencies(dict(final_model.show_topic(topic_id, topn=20)))\n",
    "        ax[i, j].set_title(f'Topic: {topic_id}')\n",
    "        ax[i, j].imshow(wordcloud)\n",
    "        ax[i, j].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word clouds for all topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 topics\n",
    "\n",
    "nrow = 5\n",
    "ncol = 6\n",
    "fig, ax = plt.subplots(nrow, ncol, figsize=(60, 40), sharex='row', constrained_layout=True)\n",
    "aux_id = 0\n",
    "\n",
    "topic_ids = range(30)\n",
    "\n",
    "for i in range(nrow):\n",
    "    for j in range(ncol):\n",
    "        topic_id = topic_ids[(aux_id)]\n",
    "        aux_id += 1\n",
    "        wordcloud = WordCloud(background_color='white', collocations=False, max_words=20).generate_from_frequencies(dict(final_model.show_topic(topic_id, topn=20)))\n",
    "        ax[i, j].set_title(f'Topic: {topic_id}', fontsize=45)\n",
    "        ax[i, j].imshow(wordcloud)\n",
    "        ax[i, j].axis('off')\n",
    "plt.savefig(f'word_clouds_lda_{NUM_TOPICS}.png') # Save into a file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
